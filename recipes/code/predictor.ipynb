{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51665306-7c67-4361-98cb-2379f66b46a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Connecting to &#x27;trino://streambased-server:8080/kafka&#x27;</span>"
      ],
      "text/plain": [
       "Connecting to 'trino://streambased-server:8080/kafka'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;trino://streambased-server:8080/kafka&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'trino://streambased-server:8080/kafka'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext sql\n",
    "%sql trino://streambased-server:8080/kafka\n",
    "result = %sql SELECT * FROM kafka.streambased.recipes WHERE rating = 5 LIMIT 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55518a61-b550-411c-b4d1-55ae4014fbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = result.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6894270-e456-40d1-98e9-af4dc7a263e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f2223c0-1f79-4203-adba-5d15a7bb9fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [column for column in df.columns if column not in ['rating', '_partition_id', '_partition_offset',\n",
    "                                                               '_message_corrupt', '_message', '_headers',\n",
    "                                                               '_message_length', '_key_corrupt', '_key',\n",
    "                                                               '_key_length', '_timestamp', 'cuisine']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e75a4643-5ed7-49f9-9f17-b1ff530b626d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'hoeffding_tree_model.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the pre-trained model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhoeffding_tree_model.joblib\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Simulate incoming data stream (for demonstration, let's use a portion of your existing DataFrame)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# In a real scenario, this data could come from a live data source\u001b[39;00m\n\u001b[1;32m     10\u001b[0m streaming_data \u001b[38;5;241m=\u001b[39m df[features]  \u001b[38;5;66;03m# Let's assume we're making predictions for the first 10 rows\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'hoeffding_tree_model.joblib'"
     ]
    }
   ],
   "source": [
    "from river import tree\n",
    "from joblib import load\n",
    "\n",
    "# Load the pre-trained model\n",
    "model_path = \"hoeffding_tree_model.joblib\"\n",
    "model = load(model_path)\n",
    "\n",
    "# Simulate incoming data stream (for demonstration, let's use a portion of your existing DataFrame)\n",
    "# In a real scenario, this data could come from a live data source\n",
    "streaming_data = df[features]  # Let's assume we're making predictions for the first 10 rows\n",
    "\n",
    "# Iterate over each row in your streaming data to make predictions\n",
    "for index, row in streaming_data.iterrows():\n",
    "    # Convert the row to a dict of features\n",
    "    x = row.to_dict()\n",
    "    \n",
    "    # Make a prediction for the current set of features\n",
    "    y_pred = model.predict_one(x)\n",
    "    \n",
    "    # Optionally, you can print or log the prediction\n",
    "    print(f\"Predicted class for row {index}: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6619c0-c56a-4352-b05e-7cc3d26bca4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d6b297-fb5c-486e-826b-913ba5b986f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702ae3db-1569-4aa3-9423-eac172ffd2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78849b26",
   "metadata": {},
   "source": [
    "## Load Data from kafka server "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b0bc51-9e65-4eb9-afd0-fb9d7a048696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n",
      "Deploy Dash apps for free on Ploomber Cloud! Learn more: https://ploomber.io/s/signup\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;trino://streambased-server:8080/kafka&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'trino://streambased-server:8080/kafka'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext sql\n",
    "%sql trino://streambased-server:8080/kafka\n",
    "result = %sql SELECT * FROM kafka.streambased.recipes WHERE rating = 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c953991",
   "metadata": {},
   "source": [
    "### Load the query into pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "779fdfaa-4c82-4f90-b5d3-a5970730a53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = result.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36adb8e5",
   "metadata": {},
   "source": [
    "### Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20ef1745-92fd-44a2-8b6b-1d464d5ea474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from joblib import dump, load\n",
    "from river import tree, compose, metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "726c2aac-71bb-4779-8856-f786172c32f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model initialized.\n",
      "Model Trained\n",
      "Total number of rows trained: 9123\n",
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from joblib import dump, load\n",
    "from river import tree, metrics\n",
    "\n",
    "# Assuming df is your DataFrame after loading and preprocessing\n",
    "features = [column for column in df.columns if column not in ['rating', '_partition_id', '_partition_offset',\n",
    "                                                               '_message_corrupt', '_message', '_headers',\n",
    "                                                               '_message_length', '_key_corrupt', '_key',\n",
    "                                                               '_key_length', '_timestamp', 'cuisine']]\n",
    "\n",
    "# Initialize or load the model\n",
    "model_path = \"hoeffding_tree_model.joblib\"\n",
    "try:\n",
    "    model = load(\"hoeffding_tree_model.joblib\")\n",
    "    print(\"Model loaded successfully.\")\n",
    "except Exception:\n",
    "    model = tree.HoeffdingTreeClassifier(\n",
    "        grace_period=25,  # Reduce the grace period to make the tree adapt more quickly\n",
    "        max_depth=30,  # Limit the maximum depth to control the complexity of the tree\n",
    "        split_criterion='gini',  # Use Gini impurity as the split criterion\n",
    "        leaf_prediction='nba',  # Use Naive Bayes Adaptive for leaf prediction\n",
    "        nb_threshold=10,  # Increase the number of instances required for Naive Bayes\n",
    "        binary_split=True,  # Allow only binary splits\n",
    "        min_branch_fraction=0.005,  # Lower the minimum fraction of samples required for branches\n",
    "        max_share_to_split=0.95,  # Allow splits even if the majority class share is high\n",
    "        max_size=200  # Increase the maximum size of the tree\n",
    "    )\n",
    "    print(\"New model initialized.\")\n",
    "\n",
    "# Prepare a metric to track performance\n",
    "metric = metrics.Accuracy()\n",
    "\n",
    "total_trained_rows = 0\n",
    "accuracy_values = []\n",
    "\n",
    "# Simulate a data stream and train the model incrementally\n",
    "for index, row in df.iterrows():\n",
    "    x = row[features].to_dict()\n",
    "    y = row['cuisine']\n",
    "    model.learn_one(x, y)\n",
    "    total_trained_rows += 1\n",
    "\n",
    "print(\"Model Trained\")\n",
    "print(\"Total number of rows trained:\", total_trained_rows)\n",
    "\n",
    "# Save the model\n",
    "try:\n",
    "    dump(model, model_path)\n",
    "    print(\"Model saved successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Error saving the model:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

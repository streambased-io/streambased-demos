{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0b0bc51-9e65-4eb9-afd0-fb9d7a048696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Connecting to &#x27;trino://streambased-server:8080/kafka&#x27;</span>"
      ],
      "text/plain": [
       "Connecting to 'trino://streambased-server:8080/kafka'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;trino://streambased-server:8080/kafka&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'trino://streambased-server:8080/kafka'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext sql\n",
    "%sql trino://streambased-server:8080/kafka\n",
    "result = %sql SELECT * FROM kafka.streambased.recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "779fdfaa-4c82-4f90-b5d3-a5970730a53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = result.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20ef1745-92fd-44a2-8b6b-1d464d5ea474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from joblib import dump, load\n",
    "from river import tree, compose, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "726c2aac-71bb-4779-8856-f786172c32f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m y \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuisine\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Update the model and optionally update metric\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# metric = metric.update(y, model.predict_one(x))  # Uncomment if you want to track performance\u001b[39;00m\n\u001b[1;32m     30\u001b[0m total_trained_rows \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/river/tree/hoeffding_tree_classifier.py:379\u001b[0m, in \u001b[0;36mHoeffdingTreeClassifier.learn_one\u001b[0;34m(self, x, y, w)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m weight_diff \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrace_period:\n\u001b[1;32m    378\u001b[0m                 p_branch \u001b[38;5;241m=\u001b[39m p_node\u001b[38;5;241m.\u001b[39mbranch_no(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(p_node, DTBranch) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 379\u001b[0m                 \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attempt_to_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_branch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m                 node\u001b[38;5;241m.\u001b[39mlast_split_attempt_at \u001b[38;5;241m=\u001b[39m weight_seen\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/river/tree/hoeffding_tree_classifier.py:262\u001b[0m, in \u001b[0;36mHoeffdingTreeClassifier._attempt_to_split\u001b[0;34m(self, leaf, parent, parent_branch, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m leaf\u001b[38;5;241m.\u001b[39mobserved_class_distribution_is_pure():  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     split_criterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_split_criterion()\n\u001b[0;32m--> 262\u001b[0m     best_split_suggestions \u001b[38;5;241m=\u001b[39m \u001b[43mleaf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_split_suggestions\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_criterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m     best_split_suggestions\u001b[38;5;241m.\u001b[39msort()\n\u001b[1;32m    264\u001b[0m     should_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/river/tree/nodes/htc_nodes.py:61\u001b[0m, in \u001b[0;36mLeafMajorityClass.best_split_suggestions\u001b[0;34m(self, criterion, tree)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maj_class \u001b[38;5;129;01mand\u001b[39;00m maj_class \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_weight \u001b[38;5;241m>\u001b[39m tree\u001b[38;5;241m.\u001b[39mmax_share_to_split:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [BranchFactory()]\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_split_suggestions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/river/tree/nodes/leaf.py:132\u001b[0m, in \u001b[0;36mHTLeaf.best_split_suggestions\u001b[0;34m(self, criterion, tree)\u001b[0m\n\u001b[1;32m    130\u001b[0m     best_suggestions\u001b[38;5;241m.\u001b[39mappend(null_split)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m att_id, splitter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplitters\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 132\u001b[0m     best_suggestion \u001b[38;5;241m=\u001b[39m \u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_evaluated_split_suggestion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_split_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matt_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_split\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m     best_suggestions\u001b[38;5;241m.\u001b[39mappend(best_suggestion)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_suggestions\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/river/tree/splitter/gaussian_splitter.py:62\u001b[0m, in \u001b[0;36mGaussianSplitter.best_evaluated_split_suggestion\u001b[0;34m(self, criterion, pre_split_dist, att_idx, binary_only)\u001b[0m\n\u001b[1;32m     60\u001b[0m suggested_split_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_point_suggestions()\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split_value \u001b[38;5;129;01min\u001b[39;00m suggested_split_values:\n\u001b[0;32m---> 62\u001b[0m     post_split_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_dists_from_binary_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     merit \u001b[38;5;241m=\u001b[39m criterion\u001b[38;5;241m.\u001b[39mmerit_of_split(pre_split_dist, post_split_dist)\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m merit \u001b[38;5;241m>\u001b[39m best_suggestion\u001b[38;5;241m.\u001b[39mmerit:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/river/tree/splitter/gaussian_splitter.py:97\u001b[0m, in \u001b[0;36mGaussianSplitter._class_dists_from_binary_split\u001b[0;34m(self, split_value)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     96\u001b[0m         lhs_dist[k] \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mcdf(split_value) \u001b[38;5;241m*\u001b[39m estimator\u001b[38;5;241m.\u001b[39mn_samples\n\u001b[0;32m---> 97\u001b[0m         rhs_dist[k] \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_samples\u001b[49m \u001b[38;5;241m-\u001b[39m lhs_dist[k]\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [lhs_dist, rhs_dist]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/river/proba/gaussian.py:54\u001b[0m, in \u001b[0;36mGaussian.n_samples\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m     new\u001b[38;5;241m.\u001b[39m_var \u001b[38;5;241m=\u001b[39m stats\u001b[38;5;241m.\u001b[39mVar\u001b[38;5;241m.\u001b[39m_from_state(n, m, sig, ddof\u001b[38;5;241m=\u001b[39mddof)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mn_samples\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var\u001b[38;5;241m.\u001b[39mmean\u001b[38;5;241m.\u001b[39mn\n\u001b[1;32m     58\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmu\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import necessary libraries from river\n",
    "# Assuming df is your DataFrame after loading and preprocessing\n",
    "features = [column for column in df.columns if column not in ['rating', '_partition_id', '_partition_offset',\n",
    "                                                               '_message_corrupt', '_message', '_headers',\n",
    "                                                               '_message_length', '_key_corrupt', '_key',\n",
    "                                                               '_key_length', '_timestamp', 'cuisine']]\n",
    "\n",
    "# Initialize or load the model\n",
    "model_path = \"hoeffding_tree_model.joblib\"\n",
    "try:\n",
    "    model = load(model_path)\n",
    "    print(\"Model loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    model = tree.HoeffdingTreeClassifier()\n",
    "    print(\"New model initialized.\")\n",
    "\n",
    "# Prepare a metric to track performance (optional)\n",
    "metric = metrics.Accuracy()\n",
    "\n",
    "total_trained_rows = 0\n",
    "\n",
    "# Simulate a data stream and train the model incrementally\n",
    "for index, row in df.iterrows():\n",
    "    # Extract features and target variable for the current row\n",
    "    x = row[features].to_dict()\n",
    "    y = row['cuisine']\n",
    "    # Update the model and optionally update metric\n",
    "    model.learn_one(x, y)\n",
    "    # metric = metric.update(y, model.predict_one(x))  # Uncomment if you want to track performance\n",
    "    total_trained_rows += 1\n",
    "\n",
    "# Save the updated model\n",
    "dump(model, model_path)\n",
    "print(f\"Model updated and saved. Total trained rows: {total_trained_rows}.\")\n",
    "\n",
    "# Example of making a prediction with the updated model\n",
    "# x_new = {feature: value, ...}  # New data point's features\n",
    "# y_pred = model.predict_one(x_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb10e5fe-2efa-4c47-b370-dde0a7d499c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = df['cuisine'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0266aa-18d4-4c16-8292-90bc7833cbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44612931-8a68-4cec-b211-1aecebff51a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# Streambased Log Shipping Demo

## What does this demo do?

This demo simulates one of the core use cases for Apache Kafka: Log shipping. We will run a sample application that 
creates log data that flows through Kafka.

On top of this we will use Streambased technology to analyze the captured logs in order to perform investigative tasks.

## Step 1: Setup and review the environment

First run the setup script, this will configure the resources for the demo.

```bash
./bin/setup.sh
```

Our environment consists of the following components:

1. A single node Kafka cluster (containers kafka1 and zookeeper) - for data storage
2. A Schema Registry - for governance
3. Streambased Indexer - to create the indexes Streambased uses to be fast
4. Streambased Server - to make the Kafka data available via JDBC
5. Superset - a popular and easy to use database client
6. Logging Client - a container with all Kafka client dependencies that is used to generate log messages

## Step 2: Start the environment

To bring up the environment run:

```bash
docker-compose up -d
```

## Step 3: Create Topics

Let's create the Kafka topics we need for this demo. `testTopic` will store test data to be produced and consumed by 
our test clients. `logs` will store log messages generated by those clients to be queried by Streambased.

```bash
docker-compose exec logging-client bash -c '/kafka_2.13-3.6.2/bin/kafka-topics.sh --bootstrap-server kafka1:9092 --topic testTopic --create'
docker-compose exec logging-client bash -c '/kafka_2.13-3.6.2/bin/kafka-topics.sh --bootstrap-server kafka1:9092 --topic logs --create'
```

## Step 4: Create our test clients

In our simulated pipeline we will have a single producer and a single consumer. Note that we don't actually care what 
these do and are instead focused on the log messages generated by them and captured by Streambased. In separate windows 
run the following:

```bash
docker-compose exec logging-client bash -c 'for a in {1..1000}; do echo testMessage | /kafka_2.13-3.6.2/bin/kafka-console-producer.sh --bootstrap-server kafka1:9092 --topic testTopic; done'
```

```bash
docker-compose exec logging-client bash -c '/kafka_2.13-3.6.2/bin/kafka-console-consumer.sh --bootstrap-server kafka1:9092 --topic testTopic'
```

Leave these 2 processes running throughout the demo

## Step 5: Open superset

Now we can query the collected data and demonstrate the Streambased effect. 

From a web browser navigate to `localhost:8088`. 

## Step 6: Query with Streambased

Next from the menu at the top select `SQL -> SQL Lab`, you will see a familiar SQL query interface. In the query entry 
area add the following:

```
use kafka.streambased;
select * from logs;
```

and click `RUN`

## Step 7: See the Streambased advantage

To really see the advantage of Streambased we must constrain our queries by adding `WHERE` cluaes. Make a note of the 
`timemin` and `timesecond` values from the query above and run the following new query:

```
use kafka.streambased;
select * from logs where timemin=<your timemin value> and timesecond=<your timesecond value>;
```

This query should run very fast (remember to turn the LIMIT to 100000 to make sure you get all results).

Note: Streambased is designed to operate on high volumes of data. We recommend to wait until the `logs` table has 
accumulated at least 1m rows to make the Streambased acceleration effect pronounced.

## Step 8: Compare with no Streambased acceleration

You can see how long the query will take without Streambased by disabling acceleration. Run the following to disable 
acceleration and then run the query above:

```
set session use_streambased=false;
```

Depending on how much data has been written you should see around a 10x performance degradation. 

To re-enable acceleration run:

```
set session use_streambased=true;
```

## Step 9: Explore!

Feel free to run other queries against this dataset with or without Streambased acceleration enabled

## Step 10: Tear down

To complete the demo run the following. This will stop and remove all demo resources:

```bash
docker-compose stop
docker-compsoe rm
```

## Summary

In this demo we have introduced Streambased acceleration to a simple log collection pipeline and reaped the benefits in 
adhoc SQL queries against the log dataset.
